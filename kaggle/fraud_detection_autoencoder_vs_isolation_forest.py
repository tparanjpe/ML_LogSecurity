# -*- coding: utf-8 -*-
"""fraud-detection-autoencoder-vs-isolation-forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zlYI5wo66oG3zNHvRkVoyNjXJGQrZgWl
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import matplotlib.pyplot as plt
import seaborn as sns
import datetime as dt

import torch
from sklearn.model_selection import train_test_split

pd.set_option('display.max_columns', None)
sns.set(rc = {'figure.figsize':(15,8)})

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

SEED = 42

if torch.cuda.is_available():
    DEVICE = "cuda" 
else:
    DEVICE = "cpu"
print("Selected device is",DEVICE)

"""## Loading and preprocessing the data """

df=pd.read_csv('input\\fraud-detection\\fraudTrain.csv')
df.drop_duplicates(inplace=True)
df = df.drop('Unnamed: 0', axis=1)
df['age']=dt.date.today().year-pd.to_datetime(df['dob']).dt.year
df['hour']=pd.to_datetime(df['trans_date_trans_time']).dt.hour
df['daily']=pd.to_datetime(df['trans_date_trans_time']).dt.day
df['day']=pd.to_datetime(df['trans_date_trans_time']).dt.dayofweek
df['month']=pd.to_datetime(df['trans_date_trans_time']).dt.month

from sklearn.preprocessing import LabelEncoder

labelencoder = LabelEncoder()
df['category_encoded'] = labelencoder.fit_transform(df['category'])
df['gender_encoded'] = labelencoder.fit_transform(df['gender'])
df['city_encoded'] = labelencoder.fit_transform(df['city'])
df['state_encoded'] =labelencoder.fit_transform(df['state'])
df['job_encoded'] = labelencoder.fit_transform(df['job'])

X = df[['category_encoded', 'amt', 'gender_encoded', 'city_encoded', 'state_encoded', 'city_pop', 'job_encoded', 'age', 'hour', 'daily', 'day', 'month', 'is_fraud']]
input_features = ['category_encoded', 'amt', 'gender_encoded', 'city_encoded', 'state_encoded', 'city_pop', 'job_encoded', 'age', 'hour', 'daily', 'day', 'month']

"""#### Spliting the training set into training (90%) and validation(10%) set"""

df_train, df_val = train_test_split(X, test_size=0.1, random_state=42, stratify=X['is_fraud'])

"""### We scale the data"""

from sklearn import preprocessing

scaler = preprocessing.StandardScaler()
scaler.fit(df_train[input_features])

df_train[input_features]=scaler.transform(df_train[input_features])
df_val[input_features]=scaler.transform(df_val[input_features])

X_train = df_train.iloc[:,:-1]
y_train = df_train.iloc[:,-1]
X_val = df_val.iloc[:,:-1]
y_val = df_val.iloc[:,-1]

"""### We convert our features and labels into torch tensors"""

X_train_torch = torch.FloatTensor(X_train.values)
X_val_torch = torch.FloatTensor(X_val.values)
y_train_torch = torch.FloatTensor(y_train.values)
y_val_torch = torch.FloatTensor(y_val.values)

"""#### As we all know that in case of fraud detection, companies do not always have a labeled historical data. So for this reason why we tried to rely on unsupervised learning models. We will also rely on a new dataset which receives the descriptive features of a transaction and returns it as both input and output"""

class FraudDataset(torch.utils.data.Dataset):
    
    def __init__(self, x,output=True):
        'Initialization'
        self.x = x
        self.output = output

    def __len__(self):
        'Returns the total number of samples'
        return len(self.x)

    def __getitem__(self, index):
        'Generates one sample of data'
        item = self.x[index].to(DEVICE)
        if self.output:
            return item, item
        else:
            return item

train_set = FraudDataset(X_train_torch)
val_set = FraudDataset(X_val_torch)

train_loader_params = {'batch_size': 64,
              'shuffle': True,
              'num_workers': 0}
valid_loader_params = {'batch_size': 64,
              'num_workers': 0}
    
training_generator = torch.utils.data.DataLoader(train_set, **train_loader_params)
valid_generator = torch.utils.data.DataLoader(val_set, **valid_loader_params)

"""#### We resorted to a regular feed-forward autoencoder with the following architecture:
* A first input layer with ReLu activation (input_size, intermediate_size)

* A second layer with ReLu activation (intermediate_size, code_size)

* A third layer with ReLu activation (code_size, intermediate_size)

* An output layer with linear activation (intermediate_size, input_size)
"""

class Autoencoder(torch.nn.Module):
    
        def __init__(self, input_size, intermediate_size, code_size):
            super(Autoencoder, self).__init__()
            # parameters
            self.input_size = input_size
            self.intermediate_size = intermediate_size           
            self.code_size  = code_size
            
            self.relu = torch.nn.ReLU()   
            
            #encoder
            self.fc1 = torch.nn.Linear(self.input_size, self.intermediate_size)
            self.fc2 = torch.nn.Linear(self.intermediate_size, self.code_size)
            
            #decoder 
            self.fc3 = torch.nn.Linear(self.code_size, self.intermediate_size)            
            self.fc4 = torch.nn.Linear(self.intermediate_size, self.input_size)
            

            
            
        def forward(self, x):
            
            hidden = self.fc1(x)
            hidden = self.relu(hidden)
            
            code = self.fc2(hidden)
            code = self.relu(code)
 
            hidden = self.fc3(code)
            hidden = self.relu(hidden)
            
            output = self.fc4(hidden)
            
            return output

criterion = torch.nn.MSELoss().to(DEVICE)

"""#### Our goal is to predict the input from the input. Therefore, one cannot directly use its prediction for fraud detection. Instead, the idea is to use its reconstruction error between the input and the output.

#### the reconstruction error can be considered as predicted fraud score, and therfore the higher the error, the higher the risk.
"""

def per_sample_mse(model, generator):
    
    model.eval()
    criterion = torch.nn.MSELoss(reduction="none")
    batch_losses = []
    
    for x_batch, y_batch in generator:
        # Forward pass
        y_pred = model(x_batch)
        # Compute Loss
        loss = criterion(y_pred.squeeze(), y_batch)
        loss_app = list(torch.mean(loss,axis=1).detach().cpu().numpy())
        batch_losses.extend(loss_app)
    
    return batch_losses

import time
def training_loop(model,training_generator,valid_generator,optimizer,criterion,max_epochs=100,apply_early_stopping=True,patience=4,verbose=False):
    #Setting the model in training mode
    model.train()

    if apply_early_stopping:
        early_stopping = EarlyStopping(verbose=verbose,patience=patience)
    
    all_train_losses = []
    all_valid_losses = []
    
    #Training loop
    start_time=time.time()
    for epoch in range(max_epochs):
        model.train()
        train_loss=[]
        for x_batch, y_batch in training_generator:
            optimizer.zero_grad()
            # Forward pass
            y_pred = model(x_batch)
            # Compute Loss
            loss = criterion(y_pred.squeeze(), y_batch)
            # Backward pass
            loss.backward()
            optimizer.step()   
            train_loss.append(loss.item())
        
        #showing last training loss after each epoch
        all_train_losses.append(np.mean(train_loss))
        if verbose:
            print('')
            print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))
        #evaluating the model on the test set after each epoch    
        valid_loss = evaluate_model(model,valid_generator,criterion)
        all_valid_losses.append(valid_loss)
        if verbose:
            print('valid loss: {}'.format(valid_loss))
        if apply_early_stopping:
            if not early_stopping.continue_training(valid_loss):
                if verbose:
                    print("Early stopping")
                break
        
    training_execution_time=time.time()-start_time
    return model,training_execution_time,all_train_losses,all_valid_losses

class EarlyStopping:
    
    def __init__(self, patience=4, verbose=False):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = np.Inf
    
    def continue_training(self,current_score):
        if self.best_score > current_score:
            self.best_score = current_score
            self.counter = 0
            if self.verbose:
                print("New best score:", current_score)
        else:
            self.counter+=1
            if self.verbose:
                print(self.counter, " iterations since best score.")
                
        return self.counter <= self.patience

def evaluate_model(model,generator,criterion):
    model.eval()
    batch_losses = []
    for x_batch, y_batch in generator:
        # Forward pass
        y_pred = model(x_batch)
        # Compute Loss
        loss = criterion(y_pred.squeeze(), y_batch)
        batch_losses.append(loss.item())
    mean_loss = np.mean(batch_losses)    
    return mean_loss

model = Autoencoder(len(input_features), 200,12).to(DEVICE)

optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)

"""#### Let's start out training, we set our max epochs to 200, and patience to 1 to stop optimization with early stopping using validation data"""

model,training_execution_time,train_losses,valid_losses = training_loop(model,
                                                                        training_generator,
                                                                        valid_generator,
                                                                        optimizer,
                                                                        criterion,
                                                                        max_epochs=200,
                                                                        patience=1,
                                                                        verbose=True)

losses = per_sample_mse(model, valid_generator)
print(np.mean(losses))

print(X_train_torch[0])
print(model(X_train_torch[0].to(DEVICE)))

genuine_losses = np.array(losses)[y_val_torch.cpu().numpy() == 0]
fraud_losses = np.array(losses)[y_val_torch.cpu().numpy() == 1]
print("Average fraud reconstruction error:", np.mean(fraud_losses))
print("Average genuine reconstruction error:", np.mean(genuine_losses))

"""#### After comparing the reconstructed error between fraud and genuine transactions, it appears that fraud are less well reconstructed than genuine transactions"""

predictions_df_AE=df_val.copy()
predictions_df_AE['predictions_loss']=losses

threshold_AE = np.percentile(predictions_df_AE['predictions_loss'],95)

predictions_df_AE['predictions'] = [1 if x > threshold_AE else 0 for x in predictions_df_AE['predictions_loss']]
predictions_df_AE

from sklearn import metrics
def performance_assessment(predictions_df, output_feature='is_fraud', 
                           prediction_feature='predictions', rounded=True):
    
    AUC_ROC = metrics.roc_auc_score(predictions_df[output_feature], predictions_df[prediction_feature])
    AP = metrics.average_precision_score(predictions_df[output_feature], predictions_df[prediction_feature])
    
    performances = pd.DataFrame([[AUC_ROC, AP]], 
                           columns=['AUC ROC','Average precision'])
    performances = performances.round(3)
    
    return performances

performance_assessment(predictions_df_AE)

"""## Evaluating the model on the testing set"""

df_test=pd.read_csv('input\\fraud-detection\\fraudTest.csv')
df_test.drop_duplicates(inplace=True)
df_test = df_test.drop('Unnamed: 0', axis=1)
df_test['age']=dt.date.today().year-pd.to_datetime(df_test['dob']).dt.year
df_test['hour']=pd.to_datetime(df_test['trans_date_trans_time']).dt.hour
df_test['daily']=pd.to_datetime(df_test['trans_date_trans_time']).dt.day
df_test['day']=pd.to_datetime(df_test['trans_date_trans_time']).dt.dayofweek
df_test['month']=pd.to_datetime(df_test['trans_date_trans_time']).dt.month

labelencoder1 = LabelEncoder()
df_test['category_encoded'] = labelencoder1.fit_transform(df_test['category'])
df_test['gender_encoded'] = labelencoder1.fit_transform(df_test['gender'])
df_test['city_encoded'] = labelencoder1.fit_transform(df_test['city'])
df_test['state_encoded'] =labelencoder1.fit_transform(df_test['state'])
df_test['job_encoded'] = labelencoder1.fit_transform(df_test['job'])

df_test = df_test[['category_encoded', 'amt', 'gender_encoded', 'city_encoded', 'state_encoded', 'city_pop', 'job_encoded', 'age', 'hour', 'daily', 'day', 'month', 'is_fraud']]

scaler = preprocessing.StandardScaler()
scaler.fit(df_test[input_features])

df_test[input_features]=scaler.transform(df_test[input_features])

X_test = df_test.iloc[:,:-1]
y_test = df_test.iloc[:,-1]
X_test_torch = torch.FloatTensor(X_test.values)
y_test_torch = torch.FloatTensor(y_test.values)

test_set = FraudDataset(X_test_torch)

test_loader_params = {'batch_size': 64,
              'num_workers': 0}
    
test_generator = torch.utils.data.DataLoader(test_set, **test_loader_params)

test_losses = per_sample_mse(model, test_generator)
print(np.mean(test_losses))

predictions_df_AE_test=df_test.copy()
predictions_df_AE_test['predictions_loss']=test_losses

predictions_df_AE_test['predictions'] = [1 if x > threshold_AE else 0 for x in predictions_df_AE_test['predictions_loss']]
predictions_df_AE_test

performance_assessment(predictions_df_AE_test)

"""## Isolation Forest VS AutoEncoder

#### Isolation forests are an ensemble machine learning algorithm used for anomaly detection. They work by randomly partitioning the feature space and then making a decision tree. Points that are easier to isolate (i.e., require fewer splits) are considered to be anomalies. This approach is effective when the anomalies are well separated from the normal data points, and the anomalies are more scattered throughout the feature space.
"""

df_val

from sklearn.ensemble import IsolationForest

anomalyclassifier = IsolationForest(random_state=SEED, n_estimators=40)
anomalyclassifier.fit(df_train[input_features])

predictions_df_IF = df_val.copy()
predictions_df_IF['predictions_prob'] = -anomalyclassifier.score_samples(df_val[input_features])

threshold = np.percentile(predictions_df_IF['predictions_prob'],95)

predictions_df_IF['predictions'] = [1 if x > threshold else 0 for x in predictions_df_IF['predictions_prob']]
predictions_df_IF

performance_assessment(predictions_df_IF)

"""## Evaluating the Isolation Forest model on the testing set"""

predictions_df_IF_test = df_test.copy()
predictions_df_IF_test['predictions_prob'] = -anomalyclassifier.score_samples(df_test[input_features])

predictions_df_IF_test['predictions'] = [1 if x > threshold else 0 for x in predictions_df_IF_test['predictions_prob']]
predictions_df_IF_test

performance_assessment(predictions_df_IF_test)

"""# Conclusion

### Both autoencoders and isolation forests have their strengths and weaknesses, and the best choice for a particular problem will depend on the characteristics of the data and the specific requirements of the problem. In some cases, a combination of both techniques might produce the best results.

### In conclusion, for the problem at hand, AutoEncoder was able to detect fraud more accuractly than our Isolation Forest (AUC_ROC Score of 0.75 vs 0.71 for validation set and 0.75 vs 0.69 for testing set)
"""